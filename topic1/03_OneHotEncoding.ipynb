{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "417880eb038c49c346aaca12af5a57d5875e15532e722506ed6731d77d3493bc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Practice 3 - Manual Function for One-hot encoding of text\n",
    "### Strictly used for internal purpose in Singapore Polytechnic. Do not disclose!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['students are learning nlp',\n",
       " 'nlp workshop is interesting',\n",
       " 'students are studying math',\n",
       " 'math is foundation of nlp']"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "documents = [\"Students are learning NLP.\",\n",
    "             \"NLP workshop is interesting\",\n",
    "             \"Students are studying math\",\n",
    "             \"Math is foundation of NLP\"]\n",
    "processed_docs = [doc.lower().replace(\".\",\"\") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'students': 0, 'are': 1, 'learning': 2, 'nlp': 3, 'workshop': 4, 'is': 5, 'interesting': 6, 'studying': 7, 'math': 8, 'foundation': 9, 'of': 10}\n"
     ]
    }
   ],
   "source": [
    "#Build the vocabulary\n",
    "vocab = {}\n",
    "id = 0\n",
    "for doc in processed_docs:\n",
    "    for word in doc.split():\n",
    "        if word not in vocab:\n",
    "            vocab[word] = id\n",
    "            id +=1\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one hot representation for any string based on this vocabulary. \n",
    "#If the word exists in the vocabulary, its representation is returned. \n",
    "#If not, a list of zeroes is returned for that word. \n",
    "def get_onehot_vector(somestring):\n",
    "    onehot_encoded = []\n",
    "    for word in somestring.split():\n",
    "        temp = [0]*len(vocab)\n",
    "        if word in vocab:\n",
    "            temp[vocab[word]] = 1\n",
    "        onehot_encoded.append(temp)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nlp workshop is interesting\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "print(processed_docs[1])\n",
    "get_onehot_vector(processed_docs[1]) #one hot representation for a text from our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "#one hot representation for a random text, using the above vocabulary\n",
    "get_onehot_vector(\"nlp is harder than math\") "
   ]
  },
  {
   "source": [
    "## One-hot encoding using scikit -learn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = 'can i eat the pizza you can eat the pizza'\n",
    "values = S1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The data:  ['can', 'i', 'eat', 'the', 'pizza', 'you', 'can', 'eat', 'the', 'pizza']\n\nLabel Encoded: [0 2 1 4 3 5 0 1 4 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "print(\"The data: \",values)\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "print(\"\\nLabel Encoded:\",integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The data:  ['can', 'i', 'eat', 'the', 'pizza', 'you', 'can', 'eat', 'the', 'pizza']\n\nOne-hot Encoded:\n [[1. 0. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0.]\n [0. 0. 0. 0. 0. 1.]\n [1. 0. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One-hot Encoding\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded.reshape(-1, 1))\n",
    "print(\"The data: \", values)\n",
    "print(\"\\nOne-hot Encoded:\\n\",onehot_encoded)"
   ]
  }
 ]
}