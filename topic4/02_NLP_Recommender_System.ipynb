{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "417880eb038c49c346aaca12af5a57d5875e15532e722506ed6731d77d3493bc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Practical 2. Building a simple NLP recommender system using NLTK and Gensim\n",
    "### Strictly used for internal purpose in Singapore Polytechnic. Do not disclose!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset’s README to understand the data format. \n",
    "data_path = \"data/booksummaries.txt\"\n",
    "mydata = {} #titles-summaries dictionary object\n",
    "for line in open(data_path, encoding=\"utf-8\"):\n",
    "    temp = line.split(\"\\t\")\n",
    "    mydata[temp[2]] = temp[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are totally 16277 books summary\n"
     ]
    }
   ],
   "source": [
    "print(f'There are totally {len(mydata)} books summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\" The book's two central characters are Edward Mackley, an Arctic explorer who went missing during an expedition at the turn of the 20th Century, and his great-grand-niece Julia, who lives a hundred years later. On a hot summer's day Julia begins sorting through the belongings she has inherited from her uncle, while trying to ignore the cracks which are appearing in her marriage. However, as the day wears on she makes a discovery that forces her to re-evaluate her long-held image of her uncle, her husband Simon faces a choice that will decide the future of their relationship.\\n\""
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Summary of the book \"The Still Point\"\n",
    "mydata['The Still Point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the data for doc2vec, build and save a doc2vec model\n",
    "train_doc2vec = [TaggedDocument((word_tokenize(mydata[t])), tags=[t]) for t in mydata.keys()]\n",
    "model = Doc2Vec(vector_size=50, alpha=0.025, min_count=10, dm =1, epochs=100)\n",
    "model.build_vocab(train_doc2vec)\n",
    "model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load to models\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "#This is a sentence from the summary of “Animal Farm” on Wikipedia:\n",
    "#https://en.wikipedia.org/wiki/Animal_Farm\n",
    "sample = \"Napoleon enacts changes to the governance structure of the farm, replacing meetings with a committee of pigs who will run the farm.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('Animal Farm', 0.7089385986328125), ('The Wild Irish Girl', 0.6452783942222595), ('The Big Country', 0.6087993383407593), (\"Snowball's Chance\", 0.5922266244888306), ('Poor White', 0.587264895439148), ('Tros of Samothrace', 0.5770907998085022), (\"Doctor Dolittle's Circus\", 0.5759703516960144), ('Texas Fever', 0.5660212635993958), ('The House with the Green Shutters', 0.5610345602035522), ('Scarlet Feather', 0.5589443445205688)]\n"
     ]
    }
   ],
   "source": [
    "# Use the model to look for similar books\n",
    "new_vector = model.infer_vector(word_tokenize(sample))\n",
    "sims = model.docvecs.most_similar([new_vector]) #gives 10 most similar titles\n",
    "print(sims)"
   ]
  }
 ]
}